{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modules.texts import Vocab, GloVeLoader\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from modules.layers import SentenceEncoder, DocumentEncoder, ExtractorCell\n",
    "from modules.data import DocumentDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pretrained vector file to use: /home/yhs/data/NLP/word_embeddings/GloVe/glove.6B.300d.txt\n",
      "The number of words in the pretrained vector: 400000\n",
      "The dimension of the pretrained vector: 300\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained embedding into the memory\n",
    "path_glove = os.path.join(os.path.expanduser('~'),\n",
    "             'data/NLP/word_embeddings/GloVe/glove.6B.300d.txt')\n",
    "glove = GloVeLoader(path_glove)\n",
    "\n",
    "# Load the dataset\n",
    "file = './data/Trump.txt'\n",
    "with open(file) as f:\n",
    "#     vocab = Vocab(f.read(), top_k = 50)\n",
    "    vocab = Vocab(f.read())\n",
    "\n",
    "d = 300\n",
    "emb = nn.Embedding(vocab.V, d)\n",
    "for word in vocab.word2id:\n",
    "    try:\n",
    "        emb.weight.data[vocab[word]] = torch.from_numpy(glove[word])\n",
    "    except KeyError as e:\n",
    "        # Case when pretrained embedding for a word does not exist\n",
    "        pass\n",
    "# emb.weight.requires_grad = False # suppress updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = DocumentDataset(file, vocab)\n",
    "docloader = DataLoader(doc, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 / Loss: 0.6908168\n",
      "Epoch: 10 / Loss: 0.0762508\n",
      "Epoch: 20 / Loss: 0.0151254\n",
      "Epoch: 30 / Loss: 0.0054811\n",
      "Epoch: 40 / Loss: 0.0026618\n",
      "Epoch: 50 / Loss: 0.0014242\n",
      "Epoch: 60 / Loss: 0.0009217\n",
      "Epoch: 70 / Loss: 0.0006863\n",
      "Epoch: 80 / Loss: 0.0005508\n",
      "Epoch: 90 / Loss: 0.0004623\n"
     ]
    }
   ],
   "source": [
    "vocab_size = vocab.V\n",
    "emb_size = emb.weight.data.size(1)\n",
    "n_kernels = 50\n",
    "kernel_sizes = [1,2,3,4,5]\n",
    "pretrained = emb\n",
    "sent_size = len(kernel_sizes) * n_kernels\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "\n",
    "####WARNING: No mini-batch processing#########\n",
    "s_encoder = SentenceEncoder(vocab_size,\n",
    "                            emb_size,\n",
    "                            n_kernels,\n",
    "                            kernel_sizes,\n",
    "                            pretrained)\n",
    "d_encoder = DocumentEncoder(sent_size, hidden_size)\n",
    "ext_cell = ExtractorCell(sent_size, hidden_size)\n",
    "\n",
    "# Binary Cross-Entropy loss\n",
    "loss_fn = nn.BCELoss()\n",
    "params = list(s_encoder.parameters()) + list(d_encoder.parameters()) + list(ext_cell.parameters())\n",
    "optimizer = optim.Adam(params, lr = .005)\n",
    "\n",
    "def run_epoch(docloader):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "\n",
    "    # Encode the sentences in a document\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for input_raw, target_raw in docloader:\n",
    "        input_raw = Variable(input_raw).cuda()\n",
    "        inputs.append(s_encoder(input_raw))\n",
    "        targets.append(target.cuda())\n",
    "    \n",
    "    # Build the document representation using encoded sentences\n",
    "    d_encoded = torch.cat(inputs, dim = 0)\n",
    "    targets = Variable(torch.cat(targets, dim = 0).type(torch.FloatTensor).view(-1)).cuda()\n",
    "    #### WARNING: \"BEGINNING OF THE SENTENCE\" embedding was initialized to zero ####\n",
    "    init_sent = Variable(torch.zeros(1, d_encoded.size(1))).cuda()\n",
    "    d_final = torch.cat([init_sent, d_encoded[:-1]], dim = 0)\n",
    "    d_final = d_final.view(d_final.size(0),1,d_final.size(1))\n",
    "\n",
    "    # Initialize the d_encoder\n",
    "    h, c = d_encoder.init_h0c0(batch_size)\n",
    "    h0 = Variable(h.data)\n",
    "\n",
    "    # An input goes through the d_encoder\n",
    "    output, hn, cn = d_encoder(d_final, h, c)\n",
    "\n",
    "    # Initialize the decoder\n",
    "    ## calculate p0, h_bar0, c_bar0\n",
    "    h_ = hn.squeeze(0)\n",
    "    c_ = cn.squeeze(0)\n",
    "    p = ext_cell.init_p(h0.squeeze(0), h_)\n",
    "\n",
    "    ## calculate p_t, h_bar_t, c_bar_t\n",
    "    d_encoder_hiddens = torch.cat((h0, output[:-1]), 0) #h0 ~ h_{n-1}\n",
    "    extract_probs = Variable(torch.zeros(len(inputs))).cuda()\n",
    "    for i, (s, h) in enumerate(zip(inputs, d_encoder_hiddens)):\n",
    "        h_, c_, p = ext_cell(s, h, h_, c_, p)\n",
    "        extract_probs[i] = p\n",
    "\n",
    "    optimizer.zero_grad() # flush the gradients\n",
    "    loss = loss_fn(extract_probs, targets)\n",
    "    epoch_loss += loss.data.cpu().numpy()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return epoch_loss\n",
    "\n",
    "def train(docloader, n_epochs = 100, print_every = 10):\n",
    "    total_loss = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = run_epoch(docloader)\n",
    "        if epoch % print_every == 0:\n",
    "            print('Epoch: %2i / Loss: %.7f' % (epoch, epoch_loss))\n",
    "        \n",
    "# Initial Training\n",
    "train(docloader, n_epochs = 100, print_every = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47619047619\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test(docloader):\n",
    "    # Encode the sentences in a document\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for input_raw, target_raw in docloader:\n",
    "        input_raw = Variable(input_raw).cuda()\n",
    "        inputs.append(s_encoder(input_raw))\n",
    "        targets.append(target.cuda())\n",
    "    \n",
    "    # Build the document representation using encoded sentences\n",
    "    d_encoded = torch.cat(inputs, dim = 0)\n",
    "    targets = Variable(torch.cat(targets, dim = 0).type(torch.FloatTensor).view(-1)).cuda()\n",
    "    #### WARNING: \"BEGINNING OF THE SENTENCE\" embedding was initialized to zero ####\n",
    "    init_sent = Variable(torch.zeros(1, d_encoded.size(1))).cuda()\n",
    "    d_final = torch.cat([init_sent, d_encoded[:-1]], dim = 0)\n",
    "    d_final = d_final.view(d_final.size(0),1,d_final.size(1))\n",
    "\n",
    "    # Initialize the d_encoder\n",
    "    h, c = d_encoder.init_h0c0(batch_size)\n",
    "    h0 = Variable(h.data)\n",
    "\n",
    "    # An input goes through the d_encoder\n",
    "    output, hn, cn = d_encoder(d_final, h, c)\n",
    "\n",
    "    # Initialize the decoder\n",
    "    ## calculate p0, h_bar0, c_bar0\n",
    "    h_ = hn.squeeze(0)\n",
    "    c_ = cn.squeeze(0)\n",
    "    p = ext_cell.init_p(h0.squeeze(0), h_)\n",
    "\n",
    "    ## calculate p_t, h_bar_t, c_bar_t\n",
    "    d_encoder_hiddens = torch.cat((h0, output[:-1]), 0) #h0 ~ h_{n-1}\n",
    "    extract_probs = Variable(torch.zeros(len(inputs))).cuda()\n",
    "    for i, (s, h) in enumerate(zip(inputs, d_encoder_hiddens)):\n",
    "        h_, c_, p = ext_cell(s, h, h_, c_, p)\n",
    "        extract_probs[i] = p\n",
    "    \n",
    "    extract_probs = extract_probs\n",
    "    extract_probs = extract_probs.data.cpu().numpy()\n",
    "    targets = targets.data.cpu().numpy()\n",
    "    preds = np.array([1 if p > 0.5 else 0 for p in extract_probs])\n",
    "    accuracy = np.mean(preds == targets)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "preds = test(docloader)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vocab_size = vocab.V\n",
    "# emb_size = emb.weight.data.size(1)\n",
    "# n_kernels = 50\n",
    "# kernel_sizes = [1,2,3,4,5]\n",
    "# input_size = vocab.V\n",
    "# hidden_size = 100\n",
    "# batch_size = 1\n",
    "\n",
    "# ####WARNING: No mini-batch processing#########\n",
    "# s_encoder = SentenceEncoder(vocab_size,\n",
    "#                             emb_size,\n",
    "#                             n_kernels,\n",
    "#                             kernel_sizes)\n",
    "# d_encoder = DocumentEncoder(emb_size, hidden_size)\n",
    "# ext_cell = ExtractorCell(input_size, hidden_size)\n",
    "\n",
    "# # Binary Cross-Entropy loss\n",
    "# loss_fn = nn.BCELoss()\n",
    "# params = list(s_encoder.parameters()) + list(d_encoder.parameters()) + list(ext_cell.parameters())\n",
    "# optimizer = optim.Adam(params, lr = .005)\n",
    "\n",
    "# def run_epoch(input_docs, target_docs):\n",
    "    \n",
    "#     epoch_loss = 0\n",
    "    \n",
    "#     # Train over the whole document\n",
    "#     for input, target in zip(input_docs, target_docs):\n",
    "#         # flush the gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         input = Variable(input).view(input.size(0),1,input.size(1)).cuda()\n",
    "#         target = Variable(torch.FloatTensor(target)).cuda()\n",
    "\n",
    "#         # Initialize the d_encoder\n",
    "#         h, c = d_encoder.init_h0c0(batch_size)\n",
    "#         h0 = Variable(h.data)\n",
    "\n",
    "#         # An input goes through the d_encoder\n",
    "#         output, hn, cn = d_encoder(input, h, c)\n",
    "\n",
    "#         # Initialize the decoder\n",
    "#         ## calculate p0, h_bar0, c_bar0\n",
    "#         h_ = hn.squeeze(0)\n",
    "#         c_ = cn.squeeze(0)\n",
    "#         p = ext_cell.init_p(h0.squeeze(0), h_)\n",
    "\n",
    "#         ## calculate p_t, h_bar_t, c_bar_t\n",
    "#         d_encoder_hiddens = torch.cat((h0, output[:-1]), 0) #h0 ~ h_{n-1}\n",
    "#         extract_probs = Variable(torch.zeros(input.size(0))).cuda()\n",
    "#         for i, (s, h) in enumerate(zip(input, d_encoder_hiddens)):\n",
    "#             h_, c_, p = ext_cell(s, h, h_, c_, p)\n",
    "#             extract_probs[i] = p\n",
    "#         loss = loss_fn(extract_probs, target)\n",
    "#         epoch_loss += loss.data.cpu().numpy()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     return epoch_loss\n",
    "\n",
    "# def train(input_docs, target_docs, n_epochs = 100, print_every = 10):\n",
    "#     total_loss = 0.0\n",
    "#     for epoch in range(n_epochs):\n",
    "#         epoch_loss = run_epoch(input_docs, target_docs)\n",
    "#         if epoch % print_every == 0:\n",
    "#             print('Epoch: %2i / Loss: %.7f' % (epoch, epoch_loss))\n",
    "        \n",
    "# # Initial Training\n",
    "# train(input_docs, target_docs, n_epochs = 100, print_every = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
