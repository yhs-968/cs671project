{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modules.texts import Vocab, GloVeLoader\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import modules.extractive as ext\n",
    "import modules.abstractive as abs\n",
    "from modules.data import Documents\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pretrained vector file to use: /home/yhs/data/NLP/word_embeddings/GloVe/glove.6B.200d.txt\n",
      "The number of words in the pretrained vector: 400000\n",
      "The dimension of the pretrained vector: 200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the pretrained embedding into the memory\n",
    "path_glove = os.path.join(os.path.expanduser('~'),\n",
    "             'data/NLP/word_embeddings/GloVe/glove.6B.200d.txt')\n",
    "glove = GloVeLoader(path_glove)\n",
    "\n",
    "# Load the dataset\n",
    "doc_file = './data/kaggle_news_rouge1.pkl'\n",
    "docs = Documents(doc_file, n_samples=3000, vocab_size = 30000)\n",
    "vocab = docs.vocab\n",
    "\n",
    "d = 200\n",
    "emb = nn.Embedding(vocab.V, d)\n",
    "\n",
    "def init_emb(emb, vocab):\n",
    "    for word in vocab.word2id:\n",
    "        try:\n",
    "            emb.weight.data[vocab[word]] = torch.from_numpy(glove[word])\n",
    "        except KeyError as e:\n",
    "            # Case when pretrained embedding for a word does not exist\n",
    "            pass\n",
    "#     emb.weight.requires_grad = False # suppress updates\n",
    "    print('Initialized the word embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized the word embeddings.\n",
      "Epoch: 0 / Loss:(1925.684/3853.489/197622.093) / Accuracy:(0.570) / TrainingTime:6.091(min)\n",
      "Epoch: 1 / Loss:(1868.658/2206.870/124122.366) / Accuracy:(0.596) / TrainingTime:5.931(min)\n",
      "Epoch: 2 / Loss:(1835.337/1775.562/85120.634) / Accuracy:(0.614) / TrainingTime:5.857(min)\n",
      "Epoch: 3 / Loss:(1813.400/1511.152/59274.428) / Accuracy:(0.626) / TrainingTime:5.764(min)\n",
      "Epoch: 4 / Loss:(1798.090/1289.942/40900.504) / Accuracy:(0.632) / TrainingTime:5.718(min)\n",
      "Epoch: 5 / Loss:(1785.391/1098.029/27376.805) / Accuracy:(0.636) / TrainingTime:5.680(min)\n",
      "Epoch: 6 / Loss:(1772.755/933.167/17384.270) / Accuracy:(0.641) / TrainingTime:5.660(min)\n",
      "Epoch: 7 / Loss:(1758.959/792.995/10179.049) / Accuracy:(0.645) / TrainingTime:5.639(min)\n",
      "Epoch: 8 / Loss:(1742.765/673.743/5558.586) / Accuracy:(0.651) / TrainingTime:5.606(min)\n",
      "Epoch: 9 / Loss:(1723.921/571.073/3285.092) / Accuracy:(0.657) / TrainingTime:5.588(min)\n",
      "Epoch 10 finished.\n",
      "Epoch: 0 / Loss:(1701.953/483.570/2262.904) / Accuracy:(0.664) / TrainingTime:5.570(min)\n",
      "Epoch: 1 / Loss:(1676.111/410.641/1727.900) / Accuracy:(0.672) / TrainingTime:5.551(min)\n",
      "Epoch: 2 / Loss:(1645.537/349.093/1400.014) / Accuracy:(0.681) / TrainingTime:5.533(min)\n",
      "Epoch: 3 / Loss:(1609.116/299.041/1177.907) / Accuracy:(0.691) / TrainingTime:5.512(min)\n",
      "Epoch: 4 / Loss:(1564.968/257.826/1015.054) / Accuracy:(0.701) / TrainingTime:5.498(min)\n",
      "Epoch: 5 / Loss:(1511.299/223.928/889.686) / Accuracy:(0.714) / TrainingTime:5.481(min)\n",
      "Epoch: 6 / Loss:(1447.585/195.589/792.556) / Accuracy:(0.728) / TrainingTime:5.460(min)\n",
      "Epoch: 7 / Loss:(1373.788/171.820/710.293) / Accuracy:(0.746) / TrainingTime:5.427(min)\n",
      "Epoch: 8 / Loss:(1290.517/151.855/643.013) / Accuracy:(0.765) / TrainingTime:5.399(min)\n",
      "Epoch: 9 / Loss:(1210.748/136.040/584.471) / Accuracy:(0.781) / TrainingTime:5.370(min)\n",
      "Epoch 20 finished.\n",
      "Epoch: 0 / Loss:(1125.831/123.058/536.223) / Accuracy:(0.797) / TrainingTime:5.345(min)\n",
      "Epoch: 1 / Loss:(1490.659/125.269/504.142) / Accuracy:(0.781) / TrainingTime:5.457(min)\n",
      "Epoch: 2 / Loss:(1206.058/110.789/468.117) / Accuracy:(0.806) / TrainingTime:5.386(min)\n",
      "Epoch: 3 / Loss:(1044.654/96.949/432.048) / Accuracy:(0.816) / TrainingTime:5.350(min)\n",
      "Epoch: 4 / Loss:(998.513/93.582/408.705) / Accuracy:(0.823) / TrainingTime:5.368(min)\n",
      "Epoch: 5 / Loss:(924.338/88.644/385.715) / Accuracy:(0.835) / TrainingTime:5.334(min)\n",
      "Epoch: 6 / Loss:(903.279/77.256/369.595) / Accuracy:(0.840) / TrainingTime:5.349(min)\n",
      "Epoch: 7 / Loss:(860.166/81.179/347.867) / Accuracy:(0.843) / TrainingTime:5.351(min)\n",
      "Epoch: 8 / Loss:(841.154/69.538/330.164) / Accuracy:(0.850) / TrainingTime:5.362(min)\n",
      "Epoch: 9 / Loss:(814.239/70.415/316.594) / Accuracy:(0.855) / TrainingTime:5.345(min)\n",
      "Epoch 30 finished.\n",
      "Epoch: 0 / Loss:(734.405/59.492/299.760) / Accuracy:(0.866) / TrainingTime:5.356(min)\n",
      "Epoch: 1 / Loss:(716.860/55.923/286.983) / Accuracy:(0.866) / TrainingTime:5.359(min)\n",
      "Epoch: 2 / Loss:(912.799/91.959/277.542) / Accuracy:(0.845) / TrainingTime:5.359(min)\n",
      "Epoch: 3 / Loss:(752.364/57.288/264.969) / Accuracy:(0.863) / TrainingTime:5.361(min)\n",
      "Epoch: 4 / Loss:(660.240/46.242/254.820) / Accuracy:(0.878) / TrainingTime:5.358(min)\n",
      "Epoch: 5 / Loss:(628.759/49.150/245.517) / Accuracy:(0.881) / TrainingTime:5.377(min)\n",
      "Epoch: 6 / Loss:(596.306/47.948/235.404) / Accuracy:(0.888) / TrainingTime:5.367(min)\n",
      "Epoch: 7 / Loss:(579.485/41.818/230.242) / Accuracy:(0.889) / TrainingTime:5.382(min)\n",
      "Epoch: 8 / Loss:(580.849/45.430/228.133) / Accuracy:(0.889) / TrainingTime:5.387(min)\n",
      "Epoch: 9 / Loss:(656.311/52.353/213.395) / Accuracy:(0.880) / TrainingTime:5.374(min)\n",
      "Epoch 40 finished.\n",
      "Epoch: 0 / Loss:(542.273/40.523/208.153) / Accuracy:(0.895) / TrainingTime:5.368(min)\n",
      "Epoch: 1 / Loss:(526.078/34.429/201.696) / Accuracy:(0.897) / TrainingTime:5.383(min)\n",
      "Epoch: 2 / Loss:(496.705/35.395/195.482) / Accuracy:(0.902) / TrainingTime:5.384(min)\n",
      "Epoch: 3 / Loss:(466.896/33.006/190.433) / Accuracy:(0.906) / TrainingTime:5.387(min)\n",
      "Epoch: 4 / Loss:(443.566/29.123/186.915) / Accuracy:(0.910) / TrainingTime:5.379(min)\n",
      "Epoch: 5 / Loss:(445.381/30.292/182.613) / Accuracy:(0.909) / TrainingTime:5.408(min)\n",
      "Epoch: 6 / Loss:(457.760/30.170/176.239) / Accuracy:(0.908) / TrainingTime:5.402(min)\n",
      "Epoch: 7 / Loss:(429.945/29.475/171.410) / Accuracy:(0.912) / TrainingTime:5.395(min)\n",
      "Epoch: 8 / Loss:(400.456/29.443/167.162) / Accuracy:(0.915) / TrainingTime:5.390(min)\n",
      "Epoch: 9 / Loss:(1204.919/43.515/168.845) / Accuracy:(0.870) / TrainingTime:5.450(min)\n",
      "Epoch 50 finished.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "from copy import deepcopy\n",
    "from torch import optim\n",
    "import time\n",
    "from itertools import chain\n",
    "\n",
    "vocab_size = vocab.V\n",
    "emb_size = emb.weight.data.size(1)\n",
    "n_kernels = 50\n",
    "kernel_sizes = [1,2,3,4,5]\n",
    "pretrained = emb\n",
    "sent_size = len(kernel_sizes) * n_kernels\n",
    "hidden_size = 400\n",
    "num_layers = 1\n",
    "n_classes = len(docs.dclass2id)\n",
    "batch_size = 1\n",
    "torch.manual_seed(7)\n",
    "torch.cuda.manual_seed(7)\n",
    "\n",
    "init_emb(emb, vocab)\n",
    "ext_s_enc = ext.SentenceEncoder(vocab_size, emb_size,\n",
    "                                   n_kernels, kernel_sizes, pretrained)\n",
    "ext_d_enc = ext.DocumentEncoder(sent_size, hidden_size)\n",
    "ext_extc = ext.ExtractorCell(sent_size, hidden_size)\n",
    "ext_d_classifier = ext.DocumentClassifier(sent_size, n_classes)\n",
    "abs_enc = abs.EncoderRNN(emb, hidden_size, num_layers)\n",
    "abs_dec = abs.AttnDecoderRNN(emb, hidden_size * 2, num_layers)\n",
    "\n",
    "models = [ext_s_enc, ext_d_enc, ext_extc, ext_d_classifier,\n",
    "         abs_enc, abs_dec]\n",
    "params = list(chain(*[model.parameters() for model in models]))\n",
    "optimizer = optim.SGD(params, lr = .005)\n",
    "\n",
    "loss_fn_ext = nn.BCELoss()\n",
    "loss_fn_dclass = nn.NLLLoss()\n",
    "loss_fn_abs = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_accuracy(probs, targets, verbose = False):   \n",
    "    '''\n",
    "    Calculates the accuracy for the extractor\n",
    "\n",
    "    Args:\n",
    "        probs: extraction probability\n",
    "        targets: ground truth labels for extraction\n",
    "    '''\n",
    "    import numpy as np\n",
    "    preds = np.array([1 if p > 0.5 else 0 for p in probs])\n",
    "    if verbose:\n",
    "        print(preds)\n",
    "    accuracy = np.mean(preds == targets)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# class RougeScorer:\n",
    "#     def __init__(self):\n",
    "#         from rouge import Rouge\n",
    "#         self.rouge = Rouge()\n",
    "#     def score(self, reference, generated, type = 1):\n",
    "#         score = self.rouge.get_scores(reference, generated, avg=True)\n",
    "#         score = score['rouge-%s' % type]['f']\n",
    "#         return score\n",
    "\n",
    "# rouge = RougeScorer()\n",
    "    \n",
    "def run_epoch(docs):\n",
    "    \n",
    "    epoch_loss_abs = 0\n",
    "    epoch_loss_ext = 0\n",
    "    epoch_loss_dclass = 0\n",
    "    epoch_accuracy_ext = 0\n",
    "\n",
    "    for doc in docs:\n",
    "        optimizer.zero_grad()\n",
    "        docloader = DataLoader(doc, batch_size=1, shuffle=False)\n",
    "        # Encode the sentences in a document\n",
    "        sents_raw = []\n",
    "        sents_encoded = []\n",
    "        ext_labels = []\n",
    "        doc_class = Variable(torch.LongTensor([doc.doc_class])).cuda()\n",
    "        for sent, ext_label in docloader:\n",
    "            # only accept sentences that conforms the maximum kernel sizes\n",
    "            if sent.size(1) < max(kernel_sizes):\n",
    "                continue\n",
    "            sent = Variable(sent).cuda()\n",
    "            sents_raw.append(sent)\n",
    "            sents_encoded.append(ext_s_enc(sent))\n",
    "            ext_labels.append(ext_label.cuda())\n",
    "        # Ignore if the content is a single sentence(no need to train)\n",
    "        if len(sents_raw) <= 1:\n",
    "            continue\n",
    "\n",
    "        # Build the document representation using encoded sentences\n",
    "        d_encoded = torch.cat(sents_encoded, dim = 0).unsqueeze(1)\n",
    "        ext_labels = Variable(torch.cat(ext_labels, dim = 0).type(torch.FloatTensor).view(-1)).cuda()\n",
    "        init_sent = ext_s_enc.init_sent(batch_size)\n",
    "        d_ext = torch.cat([init_sent, d_encoded[:-1]], dim = 0)\n",
    "\n",
    "        # Extractive Summarizer\n",
    "        ## Initialize the d_encoder\n",
    "        h, c = ext_d_enc.init_h0c0(batch_size)\n",
    "        h0 = Variable(h.data)\n",
    "        ## An input goes through the document encoder\n",
    "        output, hn, cn = ext_d_enc(d_ext, h, c)\n",
    "        ## Initialize the decoder\n",
    "        ### calculate p0, h_bar0, c_bar0\n",
    "        h_ = hn.squeeze(0)\n",
    "        c_ = cn.squeeze(0)\n",
    "        p = ext_extc.init_p(h0.squeeze(0), h_)\n",
    "        ### calculate p_t, h_bar_t, c_bar_t\n",
    "        d_encoder_hiddens = torch.cat((h0, output[:-1]), 0) #h0 ~ h_{n-1}\n",
    "        extract_probs = Variable(torch.zeros(len(sents_encoded))).cuda()\n",
    "        for i, (s, h) in enumerate(zip(sents_encoded, d_encoder_hiddens)):\n",
    "            h_, c_, p = ext_extc(s, h, h_, c_, p)\n",
    "            extract_probs[i] = p\n",
    "        ## Document Classifier\n",
    "        q = ext_d_classifier(extract_probs.view(-1,1), d_encoded.squeeze(1))\n",
    "        \n",
    "        ## Optimize over the extractive examples\n",
    "        loss_ext = loss_fn_ext(extract_probs, ext_labels)\n",
    "        loss_dclass = loss_fn_dclass(q.view(1,-1), doc_class)\n",
    "        epoch_loss_ext += loss_ext.data.cpu().numpy()[0]\n",
    "        epoch_loss_dclass += loss_dclass.data.cpu().numpy()[0]\n",
    "        torch.autograd.backward([loss_ext, loss_dclass])\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## Measure the accuracy\n",
    "        p_cpu = extract_probs.data.cpu().numpy()\n",
    "        t_cpu = ext_labels.data.cpu().numpy()\n",
    "        q_cpu = q.data.cpu().numpy()\n",
    "        c_cpu = doc_class.data.cpu().numpy()\n",
    "        epoch_accuracy_ext += get_accuracy(p_cpu, t_cpu)\n",
    "\n",
    "        # Abstractive Summarizer\n",
    "        optimizer.zero_grad()\n",
    "        loss_abs = 0\n",
    "        ## Run through the encoder\n",
    "#         words = torch.cat(sents_ext, dim=1).t()\n",
    "        sents_ext = [sent for i,sent in enumerate(sents_raw)\n",
    "                     if extract_probs[i].data.cpu().numpy() > 0.5]\n",
    "        \n",
    "        # skip if no sentences are selected as summaries\n",
    "        if len(sents_ext) == 0:\n",
    "            continue\n",
    "        words = torch.cat(sents_ext, dim=1).t()\n",
    "\n",
    "        abs_enc_hidden = abs_enc.init_hidden(batch_size)\n",
    "        abs_enc_output, abs_enc_hidden = abs_enc(words, abs_enc_hidden)\n",
    "        ## Remove to too long documents to tackle memory overflow\n",
    "        if len(abs_enc_output) > 6000:\n",
    "            continue\n",
    "        ## Run through the decoder\n",
    "        abs_dec_hidden = abs_dec.init_hidden(batch_size)\n",
    "        for target in doc.head:\n",
    "            target = Variable(torch.LongTensor([target]).unsqueeze(1)).cuda()\n",
    "            abs_dec_output, abs_dec_hidden, attn_weights = abs_dec(target, abs_dec_hidden, abs_enc_output)\n",
    "            loss_abs += loss_fn_abs(abs_dec_output, target.squeeze(1))\n",
    "\n",
    "        epoch_loss_abs += loss_abs.data.cpu().numpy()[0]\n",
    "        loss_abs.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    acc_ext = epoch_accuracy_ext / len(docs)\n",
    "    \n",
    "    return epoch_loss_ext, epoch_loss_dclass, epoch_loss_abs, acc_ext\n",
    "\n",
    "def train(docs, n_epochs = 10, print_every = 1):\n",
    "    import time\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "        ext_loss, dclass_loss, abs_loss, ext_acc = run_epoch(docs)\n",
    "        end_time = time.time()\n",
    "        wall_clock = (end_time - start_time) / 60\n",
    "        if epoch % print_every == 0:\n",
    "            print('Epoch:%2i / Loss:(%.3f/%.3f/%.3f) / Accuracy:(%.3f) / TrainingTime:%.3f(min)' %\n",
    "                  (epoch, ext_loss, dclass_loss, abs_loss, ext_acc, wall_clock))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized the word embeddings.\n"
     ]
    }
   ],
   "source": [
    "from os.path import join\n",
    "\n",
    "vocab_size = vocab.V\n",
    "emb_size = emb.weight.data.size(1)\n",
    "n_kernels = 50\n",
    "kernel_sizes = [1,2,3,4,5]\n",
    "pretrained = emb\n",
    "sent_size = len(kernel_sizes) * n_kernels\n",
    "hidden_size = 400\n",
    "num_layers = 1\n",
    "n_classes = len(docs.dclass2id)\n",
    "batch_size = 1\n",
    "\n",
    "init_emb(emb, vocab)\n",
    "ext_s_enc = ext.SentenceEncoder(vocab_size, emb_size,\n",
    "                                   n_kernels, kernel_sizes, pretrained)\n",
    "ext_d_enc = ext.DocumentEncoder(sent_size, hidden_size)\n",
    "ext_extc = ext.ExtractorCell(sent_size, hidden_size)\n",
    "ext_d_classifier = ext.DocumentClassifier(sent_size, n_classes)\n",
    "abs_enc = abs.EncoderRNN(emb, hidden_size, num_layers)\n",
    "abs_dec = abs.AttnDecoderRNN(emb, hidden_size * 2, num_layers)\n",
    "\n",
    "model_home = join(os.path.expanduser('~'), 'cs671-large')\n",
    "model_dict = dict()\n",
    "model_dict['emb'] = emb\n",
    "model_dict['ext_s_enc'] = ext_s_enc\n",
    "model_dict['ext_d_enc'] = ext_d_enc\n",
    "model_dict['ext_extc'] = ext_extc\n",
    "model_dict['ext_d_classifier'] = ext_d_classifier\n",
    "model_dict['abs_enc'] = abs_dec\n",
    "model_dict['abs_dec'] = abs_dec\n",
    "\n",
    "for name, model in model_dict.items():\n",
    "    model.load_state_dict(torch.load(join(model_home, name + '_epoch_50')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abs_edc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-27e65d48e0da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mabs_edc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'abs_edc' is not defined"
     ]
    }
   ],
   "source": [
    "abs_edc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class RougeScorer:\n",
    "#     def __init__(self):\n",
    "#         from rouge import Rouge\n",
    "#         self.rouge = Rouge()\n",
    "#     def score(self, reference, generated, type = 1):\n",
    "#         score = self.rouge.get_scores(reference, generated, avg=True)\n",
    "#         score = score['rouge-%s' % str(type)]['f']\n",
    "#         return score\n",
    "\n",
    "# rouge = RougeScorer()\n",
    "\n",
    "# def test(docs):\n",
    "#     '''\n",
    "#     Args:\n",
    "#         reference (str): \n",
    "#         generated (str): \n",
    "#     '''\n",
    "#     score_sum = 0\n",
    "#     for doc in docs:\n",
    "#         rouge.score(reference, generated)\n",
    "#     docs = Documents(doc_file, n_samples=2000, vocab_size = 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# docloader = DataLoader(doc, batch_size=1, shuffle=False)\n",
    "#     # Encode the sentences in a document\n",
    "#     sents_raw = []\n",
    "#     sents_encoded = []\n",
    "#     ext_labels = []\n",
    "#     doc_class = Variable(torch.LongTensor([doc.doc_class])).cuda()\n",
    "#     for sent, ext_label in docloader:\n",
    "#         # only accept sentences that conforms the maximum kernel sizes\n",
    "#         if sent.size(1) < max(kernel_sizes):\n",
    "#             continue\n",
    "#         sent = Variable(sent).cuda()\n",
    "#         sents_raw.append(sent)\n",
    "#         sents_encoded.append(ext_s_enc(sent))\n",
    "#         ext_labels.append(ext_label.cuda())\n",
    "#     # Ignore if the content is a single sentence(no need to train)\n",
    "#     if len(sents_raw) <= 1:\n",
    "#         continue\n",
    "\n",
    "#     # Build the document representation using encoded sentences\n",
    "#     d_encoded = torch.cat(sents_encoded, dim = 0).unsqueeze(1)\n",
    "#     ext_labels = Variable(torch.cat(ext_labels, dim = 0).type(torch.FloatTensor).view(-1)).cuda()\n",
    "#     init_sent = ext_s_enc.init_sent(batch_size)\n",
    "#     d_ext = torch.cat([init_sent, d_encoded[:-1]], dim = 0)\n",
    "\n",
    "#     # Extractive Summarizer\n",
    "#     ## Initialize the d_encoder\n",
    "#     h, c = ext_d_enc.init_h0c0(batch_size)\n",
    "#     h0 = Variable(h.data)\n",
    "#     ## An input goes through the document encoder\n",
    "#     output, hn, cn = ext_d_enc(d_ext, h, c)\n",
    "#     ## Initialize the decoder\n",
    "#     ### calculate p0, h_bar0, c_bar0\n",
    "#     h_ = hn.squeeze(0)\n",
    "#     c_ = cn.squeeze(0)\n",
    "#     p = ext_extc.init_p(h0.squeeze(0), h_)\n",
    "#     ### calculate p_t, h_bar_t, c_bar_t\n",
    "#     d_encoder_hiddens = torch.cat((h0, output[:-1]), 0) #h0 ~ h_{n-1}\n",
    "#     extract_probs = Variable(torch.zeros(len(sents_encoded))).cuda()\n",
    "#     for i, (s, h) in enumerate(zip(sents_encoded, d_encoder_hiddens)):\n",
    "#         h_, c_, p = ext_extc(s, h, h_, c_, p)\n",
    "#         extract_probs[i] = p\n",
    "#     ## Document Classifier\n",
    "#     q = ext_d_classifier(extract_probs.view(-1,1), d_encoded.squeeze(1))\n",
    "\n",
    "#     ## Optimize over the extractive examples\n",
    "#     loss_ext = loss_fn_ext(extract_probs, ext_labels)\n",
    "#     loss_dclass = loss_fn_dclass(q.view(1,-1), doc_class)\n",
    "#     epoch_loss_ext += loss_ext.data.cpu().numpy()[0]\n",
    "#     epoch_loss_dclass += loss_dclass.data.cpu().numpy()[0]\n",
    "# #         torch.autograd.backward([loss_ext, loss_dclass])\n",
    "#     loss_ext.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     ## Measure the accuracy\n",
    "#     p_cpu = extract_probs.data.cpu().numpy()\n",
    "#     t_cpu = ext_labels.data.cpu().numpy()\n",
    "#     q_cpu = q.data.cpu().numpy()\n",
    "#     c_cpu = doc_class.data.cpu().numpy()\n",
    "#     epoch_accuracy_ext += get_accuracy(p_cpu, t_cpu)\n",
    "#     epoch_accuracy_dclass += get_accuracy(q_cpu, c_cpu)\n",
    "\n",
    "#     # Abstractive Summarizer\n",
    "#     optimizer.zero_grad()\n",
    "#     loss_abs = 0\n",
    "#     ## Run through the encoder\n",
    "# #         words = torch.cat(sents_ext, dim=1).t()\n",
    "#     sents_ext = [sent for i,sent in enumerate(sents_raw)\n",
    "#                  if extract_probs[i].data.cpu().numpy() > 0.5]\n",
    "\n",
    "#     # skip if no sentences are selected as summaries\n",
    "#     if len(sents_ext) == 0:\n",
    "#         continue\n",
    "#     words = torch.cat(sents_ext, dim=1).t()\n",
    "\n",
    "#     abs_enc_hidden = abs_enc.init_hidden(batch_size)\n",
    "#     abs_enc_output, abs_enc_hidden = abs_enc(words, abs_enc_hidden)\n",
    "#     ## Remove to too long documents to tackle memory overflow\n",
    "#     if len(abs_enc_output) > 6000:\n",
    "#         continue\n",
    "#     ## Run through the decoder\n",
    "#     abs_dec_hidden = abs_dec.init_hidden(batch_size)\n",
    "#     for target in doc.summ:\n",
    "#         target = Variable(torch.LongTensor([target]).unsqueeze(1)).cuda()\n",
    "#         abs_dec_output, abs_dec_hidden, attn_weights = abs_dec(target, abs_dec_hidden, abs_enc_output)\n",
    "#         loss_abs += loss_fn_abs(abs_dec_output, target.squeeze(1))\n",
    "\n",
    "#     epoch_loss_abs += loss_abs.data.cpu().numpy()[0]\n",
    "# #         torch.autograd.backward([loss_ext, loss_dclass, loss_abs])\n",
    "#     loss_abs.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# acc_ext = epoch_accuracy_ext / len(docs)\n",
    "# acc_dclass = epoch_accuracy_dclass / len(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
