{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pretrained vector into the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pretrained vector file to use: /home/yhs/data/NLP/word_embeddings/GloVe/glove.6B.300d.txt\n",
      "The number of words in the pretrained vector: 400000\n",
      "The dimension of the pretrained vector: 300\n"
     ]
    }
   ],
   "source": [
    "from modules.texts import GloVeLoader\n",
    "import os\n",
    "\n",
    "path_glove = os.path.join(os.path.expanduser('~'),\n",
    "             'data/NLP/word_embeddings/GloVe/glove.6B.300d.txt')\n",
    "glove = GloVeLoader(path_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modules.texts import Vocab\n",
    "\n",
    "file = './data/Trump.txt'\n",
    "\n",
    "with open(file) as f:\n",
    "    vocab = Vocab(f.read())\n",
    "\n",
    "# Load the word embeddings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "d = 300\n",
    "emb = nn.Embedding(vocab.V, d)\n",
    "for word in vocab.word2id:\n",
    "    try:\n",
    "        emb.weight.data[vocab[word]] = torch.from_numpy(glove[word])\n",
    "    except KeyError as e:\n",
    "        # Case when pretrained embedding for a word does not exist\n",
    "        pass\n",
    "\n",
    "# emb.weight.requires_grad = False # suppress updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -9.7877e-02 -2.4622e-01  4.3475e-01  ...  -2.2616e-01 -6.1335e-01  4.4640e-01\n",
      "  5.8563e-02  9.3696e-02 -1.6048e-01  ...   1.1121e-01 -4.8603e-01  4.2183e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.8126e-01  3.1193e-01 -6.9482e-02  ...   2.3195e-01  1.4509e-01 -9.7881e-02\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x43x300]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.8671 -0.4534  0.1023  ...   0.5372 -0.6620 -0.8653\n",
      "  0.0492  0.0566  0.3676  ...  -0.4192  0.3784  0.4111\n",
      "  0.0656  0.0220 -0.1318  ...  -0.2192 -0.4319 -0.0803\n",
      "           ...             ⋱             ...          \n",
      " -0.3106 -0.1163 -0.0805  ...  -0.3994  0.3226  0.4049\n",
      " -0.1256  0.0136  0.1031  ...  -0.3422 -0.0224  0.1368\n",
      " -0.2998 -2.3583  0.5198  ...  -0.0408  0.7099  1.3563\n",
      "[torch.FloatTensor of size 1x14x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -5.2057e-01  4.9562e-01  3.2912e-02  ...  -3.5060e-01 -2.2204e-01  1.4277e-01\n",
      "  1.2615e-01  5.2901e-01 -4.7475e-02  ...  -6.3608e-01  3.5487e-01 -2.9568e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -6.9220e-01 -3.9489e-01  1.0637e-02  ...  -6.1201e-01 -1.2559e-01  2.1841e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x17x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -2.9712e-01  9.4049e-02 -9.6662e-02  ...   5.9717e-02 -2.2853e-01  2.9602e-01\n",
      "  1.1546e-01  4.8067e-01 -1.9624e-01  ...  -3.7478e-01 -3.6975e-02 -1.2239e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.1777e-02  1.4174e-01 -3.5402e-02  ...  -2.8282e-01 -3.8500e-02 -6.0507e-02\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x28x300]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -5.2057e-01  4.9562e-01  3.2912e-02  ...  -3.5060e-01 -2.2204e-01  1.4277e-01\n",
      " -1.6259e-01 -1.2535e-01  4.1657e-01  ...  -3.7834e-01 -4.2824e-01  3.0390e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -5.8483e-01 -5.0037e-02 -4.7546e-03  ...  -7.0710e-02 -4.3096e-01  1.3222e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x37x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.8671 -0.4534  0.1023  ...   0.5372 -0.6620 -0.8653\n",
      "  0.0492  0.0566  0.3676  ...  -0.4192  0.3784  0.4111\n",
      "  0.3514 -0.1685  0.1196  ...  -0.3544 -0.4076  0.4999\n",
      "           ...             ⋱             ...          \n",
      " -0.8984 -0.2424  0.5061  ...  -0.3510 -0.0012 -0.2765\n",
      " -0.1256  0.0136  0.1031  ...  -0.3422 -0.0224  0.1368\n",
      " -0.2998 -2.3583  0.5198  ...  -0.0408  0.7099  1.3563\n",
      "[torch.FloatTensor of size 1x24x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      "  1.5313e-01 -2.5466e-01 -7.7636e-02  ...  -6.2908e-02 -1.2735e-01  1.0931e-01\n",
      " -1.8559e-01 -4.1772e-01 -1.9296e-02  ...  -4.4912e-01  1.7152e-01 -7.5024e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -6.7224e-02  2.4941e-02  1.0431e-03  ...   7.2174e-02 -1.6984e-01  3.6245e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x20x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -5.2057e-01  4.9562e-01  3.2912e-02  ...  -3.5060e-01 -2.2204e-01  1.4277e-01\n",
      " -2.1060e-01  2.2677e-01  6.3678e-02  ...  -6.1045e-01 -2.0693e-01 -1.0133e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -4.7463e-01 -7.5463e-02  1.4321e-01  ...  -3.0289e-01 -3.7213e-01 -3.4922e-02\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x33x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -5.6826e-02  2.3863e-01  4.4515e-01  ...  -3.1911e-01 -2.2830e-01  1.5058e-01\n",
      " -7.6947e-02 -2.1211e-02  2.1271e-01  ...   1.8351e-01 -2.9183e-01 -4.6533e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -9.2230e-01 -2.0996e-02 -4.7249e-01  ...  -3.2695e-01 -3.4618e-01 -4.3015e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x28x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.8671 -0.4534  0.1023  ...   0.5372 -0.6620 -0.8653\n",
      "  0.0492  0.0566  0.3676  ...  -0.4192  0.3784  0.4111\n",
      " -0.3260  0.2583 -0.3910  ...  -0.5825 -0.3339 -0.0575\n",
      "           ...             ⋱             ...          \n",
      "  0.3821 -0.1536  0.4427  ...  -0.2862 -0.5672  0.9325\n",
      " -0.1256  0.0136  0.1031  ...  -0.3422 -0.0224  0.1368\n",
      " -0.2998 -2.3583  0.5198  ...  -0.0408  0.7099  1.3563\n",
      "[torch.FloatTensor of size 1x10x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -5.2057e-01  4.9562e-01  3.2912e-02  ...  -3.5060e-01 -2.2204e-01  1.4277e-01\n",
      " -1.7085e-02  2.9137e-01 -3.7638e-02  ...  -1.5451e-01  1.6863e-01  2.7054e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  3.9055e-01  2.2470e-01 -3.1008e-02  ...  -8.2866e-01 -4.2731e-02  2.9342e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x19x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      "  5.4974e-01  4.9154e-01  2.0196e-01  ...   1.2504e-01 -2.8744e-01 -3.6246e-01\n",
      " -9.4518e-03  3.1355e-01  1.8288e-01  ...   6.1209e-01 -3.0325e-01  1.5257e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  4.0968e-01 -4.8074e-01  4.0927e-01  ...  -1.9860e-01 -2.6811e-01 -2.9695e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x15x300]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -2.2130e-01  4.7139e-01 -1.6658e-01  ...  -4.0441e-01 -6.8777e-01  3.9246e-02\n",
      "  4.3591e-01  7.7794e-01  1.5586e-01  ...   8.1207e-02 -5.3821e-01  3.4390e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  5.5439e-01 -8.5219e-02 -3.1988e-01  ...   3.3660e-01 -1.2362e-02  3.7296e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x20x300]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      "  4.9177e-02  5.6631e-02  3.6762e-01  ...  -4.1919e-01  3.7843e-01  4.1108e-01\n",
      "  3.5037e-02  4.5996e-01 -6.9229e-02  ...  -4.4408e-01  4.0541e-02  9.5075e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -2.8646e-01  2.2002e-02 -3.2519e-01  ...  -8.8995e-02 -6.6424e-01  5.6724e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x23x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -5.2057e-01  4.9562e-01  3.2912e-02  ...  -3.5060e-01 -2.2204e-01  1.4277e-01\n",
      "  2.2535e-01 -9.6376e-02  4.5049e-01  ...  -2.1466e-01 -3.2486e-01  1.5221e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.6774e-01 -1.5124e-01  2.2844e-01  ...  -8.4133e-01 -4.7531e-01  1.1473e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x38x300]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -2.2130e-01  4.7139e-01 -1.6658e-01  ...  -4.0441e-01 -6.8777e-01  3.9246e-02\n",
      "  3.2327e-01  2.3192e-02  3.3958e-01  ...  -3.7025e-01 -2.8483e-01  4.8923e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  4.6349e-01 -8.7318e-02  1.1913e-02  ...  -3.0858e-01 -3.1849e-02 -5.0863e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x11x300]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -4.4399e-01  1.2817e-01 -2.5247e-01  ...  -2.0043e-01 -8.2191e-02 -6.2550e-02\n",
      " -5.3513e-02  7.6231e-01 -3.6264e-01  ...  -1.5788e-01 -1.7199e-01  3.0916e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -1.7240e-01 -4.4104e-01 -1.3103e-01  ...  -2.2135e-01  3.3503e-01 -5.5936e-02\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x24x300]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -5.2057e-01  4.9562e-01  3.2912e-02  ...  -3.5060e-01 -2.2204e-01  1.4277e-01\n",
      "  2.0556e-01  3.5533e-02  3.2222e-01  ...  -1.2533e-01 -7.4618e-01  3.1692e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.9492e-01 -2.7479e-01 -6.1668e-01  ...  -2.0710e-01  1.5589e-02  1.7391e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x11x300]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -5.2057e-01  4.9562e-01  3.2912e-02  ...  -3.5060e-01 -2.2204e-01  1.4277e-01\n",
      "  2.8814e-01  1.1413e-01 -3.0184e-01  ...  -2.4390e-01 -2.4528e-01 -8.2399e-02\n",
      "                 ...                   ⋱                   ...                \n",
      " -2.3542e-01 -4.0179e-02  1.1180e-02  ...   2.5600e-01 -4.1297e-01 -3.9296e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x29x300]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      " -4.4399e-01  1.2817e-01 -2.5247e-01  ...  -2.0043e-01 -8.2191e-02 -6.2550e-02\n",
      " -9.5487e-02 -2.0996e-01 -1.9905e-01  ...   4.3425e-02 -9.0262e-01  4.9778e-01\n",
      "                 ...                   ⋱                   ...                \n",
      " -7.7743e-03  4.6106e-01 -4.9532e-01  ...   1.9870e-01 -9.0252e-01 -3.3908e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x47x300]\n",
      "\n",
      "\n",
      " 1\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -8.6710e-01 -4.5341e-01  1.0234e-01  ...   5.3723e-01 -6.6203e-01 -8.6530e-01\n",
      "  2.8957e-01  1.7282e-02  1.1879e-01  ...  -5.7292e-01 -1.6570e-01 -1.2800e-01\n",
      "  4.9177e-02  5.6631e-02  3.6762e-01  ...  -4.1919e-01  3.7843e-01  4.1108e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.9156e-01 -5.0058e-02  1.0242e-01  ...  -7.2725e-02 -6.3089e-02  2.8448e-01\n",
      " -1.2559e-01  1.3630e-02  1.0306e-01  ...  -3.4224e-01 -2.2394e-02  1.3684e-01\n",
      " -2.9981e-01 -2.3583e+00  5.1981e-01  ...  -4.0804e-02  7.0986e-01  1.3563e+00\n",
      "[torch.FloatTensor of size 1x36x300]\n",
      "\n",
      "\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from nltk import sent_tokenize, wordpunct_tokenize\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "class DocumentDataset(Dataset):\n",
    "    '''\n",
    "    Documents dataset.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, filename, vocab, case_sensitive = False):\n",
    "        '''\n",
    "        Args:\n",
    "            filename (string): full path of the document file\n",
    "            vocab (Vocab): Vocabulary class that contains the vocabulary for a corpus\n",
    "            emb (nn.Embedding): word embeddings corresponding to the words in words_dict\n",
    "            case_sensitive (bool): whether lower/uppercase letters differ\n",
    "        '''\n",
    "        \n",
    "        with open(filename) as f:\n",
    "            raw = f.read()\n",
    "        if not case_sensitive:\n",
    "            raw = raw.lower()\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        # input sentences\n",
    "        self.inputs = vocab.sents2id(raw, case_sensitive)\n",
    "        np.random.seed(0)\n",
    "        self.targets = [np.random.randint(2) for sent in self.inputs]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = torch.LongTensor(self.inputs[idx]) \n",
    "        targets = torch.LongTensor([self.targets[idx]])\n",
    "        \n",
    "        return inputs, targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)   \n",
    "    \n",
    "doc = DocumentDataset(file, vocab)\n",
    "docloader = DataLoader(doc, batch_size=1, shuffle=False)\n",
    "\n",
    "for i,t in docloader:\n",
    "    print(emb(Variable(i)))\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the CNN sentence encoder, I have modified [this code](https://github.com/Shawn1993/cnn-text-classification-pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SentenceEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size, n_kernels, kernel_sizes, pretrained = None, static = False):\n",
    "        '''\n",
    "        Args:\n",
    "            vocab_size (int): size of the vocabulary\n",
    "            emb_size (int): dimension of word embeddings\n",
    "            n_kernels (int): the number of filters\n",
    "            kernel_sizes (int): a list of sliding windows to be used\n",
    "            static (bool): whether you want the embeddings to be updated or not\n",
    "        '''\n",
    "        super().__init__()\n",
    "        in_channels = 1\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_kernels = n_kernels\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "\n",
    "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
    "        self.init_emb(pretrained)\n",
    "        if static:\n",
    "            self.emb.weight.requires_grad = False\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(in_channels, n_kernels, (h, emb_size))\n",
    "             for h in kernel_sizes])\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.cuda()\n",
    "    \n",
    "    def init_emb(self, emb_pretrained):\n",
    "        if emb_pretrained == None:\n",
    "            return\n",
    "        else:\n",
    "            self.emb.weight = nn.Parameter(emb_pretrained.weight.data)\n",
    "\n",
    "    def forward(self, s):\n",
    "        '''\n",
    "        Args:\n",
    "            s (seq_len): a sentence of type torch.LongTensor.\n",
    "            Each entries represent a word index.\n",
    "        '''\n",
    "        # (batch_size = 1, in_channel, seq_len, emb_size)\n",
    "        s = self.emb(s).unsqueeze(1)\n",
    "        \n",
    "        feature_map = [F.relu(conv(s)).squeeze(3)\n",
    "                       for conv in self.convs]\n",
    "        feature_pooled = [F.max_pool1d(c, c.size(2)).squeeze(2)\n",
    "                          for c in feature_map]\n",
    "        feature_pooled = torch.cat(feature_pooled, 1)\n",
    "        \n",
    "        return feature_pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = emb.weight.data.size(0)\n",
    "emb_size = emb.weight.data.size(1)\n",
    "n_kernels = 50\n",
    "kernel_sizes = [1,2,3,4,5]\n",
    "sentence_encoder = SentenceEncoder(vocab_size,\n",
    "                                   emb_size,\n",
    "                                   n_kernels,\n",
    "                                   kernel_sizes,\n",
    "                                   emb)\n",
    "\n",
    "sents = []\n",
    "for input, target in docloader:\n",
    "    ####WARNING: the elements of the kernel_sizes should be larger\n",
    "    #### than the minimum length of a sentence.\n",
    "    input = Variable(input).cuda()\n",
    "    sents.append(sentence_encoder(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6579  0.5226  1.6746  ...   0.2967  0.8536  0.6642\n",
       " 0.4898  0.5226  1.6746  ...   0.1773  0.4255  0.7531\n",
       " 0.4898  0.5226  1.6746  ...   0.2306  0.6965  0.6155\n",
       "          ...             ⋱             ...          \n",
       " 0.4898  0.5226  1.6746  ...   0.2634  0.5600  0.5050\n",
       " 0.5785  0.5226  1.6746  ...   0.1486  0.6727  0.5038\n",
       " 0.4898  0.5226  1.6746  ...   0.1210  0.9029  0.4325\n",
       "[torch.cuda.FloatTensor of size 21x250 (GPU 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(sents, dim = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
