{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([\n",
       "      0     0     0  ...      0     1     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "         ...          ⋱          ...       \n",
       "      0     0     0  ...      1     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     1\n",
       "  [torch.FloatTensor of size 43x50], \n",
       "      0     0     0  ...      0     1     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      1     0     0\n",
       "         ...          ⋱          ...       \n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     1\n",
       "  [torch.FloatTensor of size 30x50], \n",
       "      0     0     0  ...      0     1     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      1     0     0\n",
       "         ...          ⋱          ...       \n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     0\n",
       "      0     0     0  ...      0     0     1\n",
       "  [torch.FloatTensor of size 61x50]],\n",
       " [[0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from custom_utils.preprocess import Vocab\n",
    "with open('./data/dl_history.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = Vocab(text, top_k = 50)\n",
    "\n",
    "print(vocab.V)\n",
    "\n",
    "sents = vocab.sents2id(text)\n",
    "# print(sents)\n",
    "# print(vocab.id2sents(sents))\n",
    "# print(vocab[0])\n",
    "# print(vocab[vocab[0]])\n",
    "\n",
    "onehot = vocab.sent2onehot(sents[0])\n",
    "# print(onehot.size())\n",
    "# print(vocab.onehot2sent(onehot))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Build the Training dataset\n",
    "input_docs = [vocab.sent2onehot(sent) for sent in sents]\n",
    "# Build inputs / targets as lists of tensors\n",
    "np.random.seed(0)\n",
    "target_docs = [np.random.randint(2, size=len(sent)).tolist()\n",
    "               for sent in input_docs]\n",
    "\n",
    "def generate_batch(inputs, targets, batch_size = 100):\n",
    "    i = 0\n",
    "    for i in range(len(inputs) // batch_size):\n",
    "        yield inputs[i:i+batch_size], targets[i:i+batch_size]\n",
    "\n",
    "next(generate_batch(input_docs, target_docs, batch_size = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the reference for general batch processing in RNNs, see [here](https://www.quora.com/How-are-inputs-fed-into-the-LSTM-RNN-network-in-mini-batch-method)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from modules.layers import DocumentEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[What operations are allowed within `forward`?(see fmassa's answers)](https://discuss.pytorch.org/t/nn-module-with-multiple-inputs/237/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExtractorCell(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # arguments\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # layers and operations\n",
    "        self.lstmc = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.h2p = nn.Linear(hidden_size * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.cuda()\n",
    "    \n",
    "    def forward(self, s, h, h_, c_, p):\n",
    "        '''\n",
    "        s: s_{t-1} (batch=1, input_size)\n",
    "        h: h_t (batch=1, hidden_size)\n",
    "        h_: hbar_{t-1} (batch=1, hidden_size)\n",
    "        c_: cbar_{t-1} (batch=1, hidden_size)\n",
    "        p: p_{t-1}. (batch=1, 1)\n",
    "        '''\n",
    "\n",
    "        s_weighted = p.expand_as(s) * s\n",
    "        h_, c_ = self.lstmc(s_weighted, (h_,c_))\n",
    "        # (batch, hidden_size*2)\n",
    "        h_cat = torch.cat([h, h_], dim = 1)\n",
    "        \n",
    "        batch_size = h_cat.size(0)\n",
    "        logit = Variable(torch.zeros(batch_size, 1))\n",
    "        if torch.cuda.is_available():\n",
    "            logit = logit.cuda()\n",
    "            \n",
    "        for b in range(batch_size):\n",
    "            logit[b] = self.h2p(h_cat[b])\n",
    "        p = self.sigmoid(logit)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            h_ = h_.cuda()\n",
    "            c_ = c_.cuda()\n",
    "            p = p.cuda()\n",
    "        \n",
    "        return h_, c_, p\n",
    "    \n",
    "    def init_p(self, h0, hn):\n",
    "        batch_size = h0.size(0)\n",
    "        h_cat = torch.cat([h0, hn], dim = 1)\n",
    "        logit = Variable(torch.zeros(batch_size, 1))\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            logit = logit.cuda()\n",
    "            \n",
    "        for b in range(batch_size):\n",
    "            logit[b] = self.h2p(h_cat[b])\n",
    "            \n",
    "        p0 = self.sigmoid(logit)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            p0 = p0.cuda()\n",
    "        \n",
    "        return p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtractorCell (\n",
       "  (lstmc): LSTMCell(50, 100)\n",
       "  (h2p): Linear (200 -> 1)\n",
       "  (sigmoid): Sigmoid ()\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extc = ExtractorCell(50, 100)\n",
    "extc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       " -0.0784  0.2611  0.0797  0.5101 -0.1945 -0.1016  0.2735  0.1839  0.3074  0.0828\n",
       " \n",
       " Columns 10 to 19 \n",
       "  0.1248  0.1799 -0.3553  0.1724  0.0806 -0.0822 -0.1091 -0.0355 -0.1199  0.0218\n",
       " \n",
       " Columns 20 to 29 \n",
       "  0.0328  0.0212  0.5700 -0.0746 -0.0072  0.0555 -0.1197 -0.4433 -0.2899  0.1244\n",
       " \n",
       " Columns 30 to 39 \n",
       " -0.1667 -0.1599 -0.2223 -0.0585  0.1371  0.0014 -0.2806  0.2987 -0.4335 -0.0183\n",
       " \n",
       " Columns 40 to 49 \n",
       "  0.0488  0.4721 -0.1027  0.0398 -0.0853 -0.6915 -0.5837 -0.1448 -0.1069 -0.0568\n",
       " \n",
       " Columns 50 to 59 \n",
       " -0.2179  0.2284 -0.0984 -0.0027  0.3182  0.3011 -0.1427  0.0650 -0.0041  0.1462\n",
       " \n",
       " Columns 60 to 69 \n",
       "  0.6825  0.0298 -0.2918 -0.1235  0.3215  0.2051  0.3010  0.2994  0.2406  0.2883\n",
       " \n",
       " Columns 70 to 79 \n",
       "  0.0498  0.0456  0.1877 -0.1237  0.1274 -0.4455  0.1771  0.0085  0.1104  0.0432\n",
       " \n",
       " Columns 80 to 89 \n",
       "  0.1121  0.0277 -0.1032  0.1760  0.0424  0.1090  0.0785  0.1958  0.4948  0.1290\n",
       " \n",
       " Columns 90 to 99 \n",
       " -0.1289  0.0440 -0.2039 -0.2040 -0.0912 -0.1883  0.1116 -0.0789  0.0169  0.2490\n",
       " [torch.cuda.FloatTensor of size 1x100 (GPU 0)], Variable containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       " -0.1145  0.7131  0.1584  1.4230 -0.3879 -0.2855  0.4745  0.3050  0.7938  0.1605\n",
       " \n",
       " Columns 10 to 19 \n",
       "  0.2445  0.3983 -0.7507  0.4194  0.1637 -0.3751 -0.2222 -0.0578 -0.2128  0.0525\n",
       " \n",
       " Columns 20 to 29 \n",
       "  0.0872  0.0308  1.1666 -0.1908 -0.0202  0.1249 -0.1805 -0.7556 -0.5932  0.4032\n",
       " \n",
       " Columns 30 to 39 \n",
       " -0.2793 -0.4299 -0.6254 -0.0910  0.5266  0.0037 -0.7301  0.5341 -0.6981 -0.0487\n",
       " \n",
       " Columns 40 to 49 \n",
       "  0.1069  1.3397 -0.2476  0.0675 -0.1797 -1.8486 -1.6399 -0.4040 -0.2963 -0.0790\n",
       " \n",
       " Columns 50 to 59 \n",
       " -0.5851  0.3401 -0.4715 -0.0044  1.5777  0.8659 -0.2074  0.3448 -0.0058  0.3065\n",
       " \n",
       " Columns 60 to 69 \n",
       "  1.3891  0.0512 -0.4332 -0.1909  0.4992  0.4864  0.8067  0.8488  0.4468  0.7247\n",
       " \n",
       " Columns 70 to 79 \n",
       "  0.1000  0.0838  0.8296 -0.2938  0.1886 -0.9517  0.5454  0.0158  0.1732  0.2100\n",
       " \n",
       " Columns 80 to 89 \n",
       "  0.1935  0.0457 -0.2497  0.4716  0.0744  0.2156  0.1514  0.4967  1.6140  0.2360\n",
       " \n",
       " Columns 90 to 99 \n",
       " -0.2461  0.0626 -0.6405 -0.3834 -0.2622 -0.6221  0.2078 -0.1509  0.0324  1.3597\n",
       " [torch.cuda.FloatTensor of size 1x100 (GPU 0)], Variable containing:\n",
       "  0.4924\n",
       " [torch.cuda.FloatTensor of size 1x1 (GPU 0)])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "s = Variable(input_docs[0][0:1]).cuda()\n",
    "h = Variable(torch.zeros(1, 100)).cuda()\n",
    "h_ = Variable(torch.randn(1, 100)).cuda()\n",
    "c_ = Variable(torch.randn(1, 100)).cuda()\n",
    "p = extc.init_p(h,h_)\n",
    "\n",
    "extc(s, h, h_, c_, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "30\n",
      "61\n",
      "15\n",
      "18\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from modules.layers import DocumentEncoder\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "from custom_utils.packing import pack, unpack\n",
    "input_size = vocab.V\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "\n",
    "####WARNING: No mini-batch processing#########\n",
    "\n",
    "encoder = DocumentEncoder(input_size, hidden_size)\n",
    "extc = ExtractorCell(input_size, hidden_size)\n",
    "        \n",
    "# Train over all the documents\n",
    "for input, target in zip(input_docs, target_docs):\n",
    "    input = Variable(input).view(input.size(0),1,input.size(1)).cuda()\n",
    "    \n",
    "    # Initialize the encoder\n",
    "    h, c = encoder.init_h0c0(batch_size)\n",
    "    h0 = Variable(h.data)\n",
    "    \n",
    "    # An input goes through the encoder\n",
    "    output, hn, cn = encoder(input, h, c)\n",
    "    \n",
    "    # Initialize the decoder\n",
    "    ## calculate p0, h_bar0, c_bar0\n",
    "    h_ = hn.squeeze(0)\n",
    "    c_ = cn.squeeze(0)\n",
    "    p = extc.init_p(h0.squeeze(0), h_)\n",
    "    \n",
    "    ## calculate p_t, h_bar_t, c_bar_t\n",
    "    i = 0\n",
    "    for s, h in zip(input, output):\n",
    "        h_, c_, p = extc(s, h, h_, c_, p)\n",
    "        i += 1\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?nn.NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?nn.BCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 / Loss: 4.1813889\n",
      "Epoch: 10 / Loss: 2.5383389\n",
      "Epoch: 20 / Loss: 3.0810349\n",
      "Epoch: 30 / Loss: 2.1359465\n",
      "Epoch: 40 / Loss: 1.5895779\n",
      "Epoch: 50 / Loss: 0.8240650\n",
      "Epoch: 60 / Loss: 0.5068389\n",
      "Epoch: 70 / Loss: 0.3069730\n",
      "Epoch: 80 / Loss: 0.1650973\n",
      "Epoch: 90 / Loss: 0.3713593\n"
     ]
    }
   ],
   "source": [
    "from modules.layers import DocumentEncoder\n",
    "import torch.optim as optim\n",
    "\n",
    "input_size = vocab.V\n",
    "hidden_size = 100\n",
    "batch_size = 1\n",
    "\n",
    "####WARNING: No mini-batch processing#########\n",
    "\n",
    "encoder = DocumentEncoder(input_size, hidden_size)\n",
    "extc = ExtractorCell(input_size, hidden_size)\n",
    "\n",
    "# Binary Cross-Entropy loss\n",
    "loss_fn = nn.BCELoss()\n",
    "params = list(encoder.parameters()) + list(extc.parameters())\n",
    "optimizer = optim.Adam(params, lr = .005)\n",
    "\n",
    "def run_epoch(input_docs, target_docs):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Train over the whole document\n",
    "    for input, target in zip(input_docs, target_docs):\n",
    "        # flush the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input = Variable(input).view(input.size(0),1,input.size(1)).cuda()\n",
    "        target = Variable(torch.FloatTensor(target)).cuda()\n",
    "\n",
    "        # Initialize the encoder\n",
    "        h, c = encoder.init_h0c0(batch_size)\n",
    "        h0 = Variable(h.data)\n",
    "\n",
    "        # An input goes through the encoder\n",
    "        output, hn, cn = encoder(input, h, c)\n",
    "\n",
    "        # Initialize the decoder\n",
    "        ## calculate p0, h_bar0, c_bar0\n",
    "        h_ = hn.squeeze(0)\n",
    "        c_ = cn.squeeze(0)\n",
    "        p = extc.init_p(h0.squeeze(0), h_)\n",
    "\n",
    "        ## calculate p_t, h_bar_t, c_bar_t\n",
    "        encoder_hiddens = torch.cat((h0, output[:-1]), 0) #h0 ~ h_{n-1}\n",
    "        extract_probs = Variable(torch.zeros(input.size(0))).cuda()\n",
    "        for i, (s, h) in enumerate(zip(input, encoder_hiddens)):\n",
    "            h_, c_, p = extc(s, h, h_, c_, p)\n",
    "            extract_probs[i] = p\n",
    "        loss = loss_fn(extract_probs, target)\n",
    "        epoch_loss += loss.data.cpu().numpy()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return epoch_loss\n",
    "\n",
    "def train(input_docs, target_docs, n_epochs = 100, print_every = 10):\n",
    "    total_loss = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = run_epoch(input_docs, target_docs)\n",
    "        if epoch % print_every == 0:\n",
    "            print('Epoch: %2i / Loss: %.7f' % (epoch, epoch_loss))\n",
    "        \n",
    "# Initial Training\n",
    "train(input_docs, target_docs, n_epochs = 100, print_every = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Good reference on PackedSequence](https://medium.com/huggingface/understanding-emotions-from-keras-to-pytorch-3ccb61d5a983)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unpacked, length = pad_packed_sequence(input_packed)\n",
    "unpacked_masked = [unpacked[:lengths[batch], batch, :]\n",
    "                   for batch in range(len(lengths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unpacked.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build inputs / targets as lists of tensors\n",
    "input_size = vocab.V\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "batch_size = 2\n",
    "\n",
    "encoder = DocumentEncoder(input_size, hidden_size, num_layers)\n",
    "decoder = SentenceExtractor(input_size, hidden_size)\n",
    "\n",
    "h, c = encoder.init_h0c0(batch_size)\n",
    "h0 = Variable(h.data)\n",
    "output = None\n",
    "encoder_hiddens = [] # the list that stores the encoder hidden states(except for h0)\n",
    "\n",
    "for minibatch in generate_batch(sentences, batch_size):\n",
    "    minibatch = minibatch.cuda()\n",
    "    _, h, c = encoder(minibatch, h, c)\n",
    "    encoder_hiddens.append(Variable(h.data))\n",
    "\n",
    "p0 = decoder.init_p(h0, h)\n",
    "s0 = decoder.init_s(batch_size)\n",
    "# initial step for the decoder\n",
    "p, h_bar, c_bar = decoder(s0, h, c, h, p0)\n",
    "\n",
    "extract_probs = []\n",
    "for minibatch, h in zip(generate_batch(sentences, batch_size), encoder_hiddens):\n",
    "    minibatch = minibatch.cuda()\n",
    "    p, h_bar, c_bar = decoder(minibatch, h_bar, c_bar, h, p)\n",
    "    extract_probs.append(p.view(-1).data.cpu().numpy()[0])\n",
    "\n",
    "print(extract_probs, len(extract_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build inputs / targets as lists of tensors\n",
    "import torch\n",
    "n_sentences = 300\n",
    "embedding_dim = 50\n",
    "sentences = torch.rand(n_sentences, embedding_dim)\n",
    "\n",
    "input_size = 50\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "batch_size = 1\n",
    "\n",
    "encoder = DocumentEncoder(input_size, hidden_size, num_layers)\n",
    "decoder = SentenceExtractor(input_size, hidden_size)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for minibatch in generate_batch(sentences, batch_size):\n",
    "        # Initialize the Encoder\n",
    "        h, c = encoder.init_h0c0(batch_size)\n",
    "        h0 = Variable(h.data)\n",
    "        encoder_hiddens = [] # the list that stores the encoder hidden states(except for h0)\n",
    "\n",
    "        minibatch = minibatch.cuda()\n",
    "        _, h, c = encoder(minibatch, h, c)\n",
    "        encoder_hiddens.append(Variable(h.data))\n",
    "\n",
    "        # Initialize the Decoder\n",
    "        loss = loss_fn\n",
    "        p0 = decoder.init_p(h0, h)\n",
    "        s0 = decoder.init_s(batch_size)\n",
    "        p, h_bar, c_bar = decoder(s0, h, c, h, p0) # initial step for the decoder    \n",
    "        extract_probs = []\n",
    "\n",
    "        for h in encoder_hiddens:\n",
    "            p, h_bar, c_bar = decoder(minibatch, h_bar, c_bar, h, p)\n",
    "            extract_probs.append(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Train the network(requires a target sequence)\n",
    "\n",
    "# input_size = vocab.V\n",
    "# hidden_size = vocab.V\n",
    "# output_size = vocab.V\n",
    "# num_layers = 1\n",
    "# batch_size = 1\n",
    "\n",
    "# encoder = Encoder(input_size, hidden_size).cuda()\n",
    "# decoder = Decoder(hidden_size, output_size).cuda()\n",
    "\n",
    "# import torch.optim as optim\n",
    "\n",
    "# loss_fn = nn.MSELoss()\n",
    "# params = list(encoder.parameters()) + list(decoder.parameters())\n",
    "# optimizer = optim.Adam(params, lr = .005)\n",
    "\n",
    "# def run_epoch(inputs, targets):\n",
    "#     # flush the gradients\n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     # initial hidden state(h0)\n",
    "#     h0,c0 = encoder.init_h0c0(batch_size = 6)\n",
    "#     # training loss\n",
    "#     loss = 0\n",
    "    \n",
    "#     # Feed the training data\n",
    "#     targets = [Variable(tensor).cuda() for tensor in targets]\n",
    "#     inputs_packed, orders = pack(inputs)\n",
    "    \n",
    "#     # Run a RNN encoder-decoder through the training samples  \n",
    "#     _, h_encoder, c_encoder = encoder(inputs_packed, h0, c0)\n",
    "#     y0 = decoder.init_pred(h_encoder)\n",
    "#     y, h_decoder, c_decoder = decoder(y0, h_encoder, c_encoder)\n",
    "    \n",
    "#     for out, target in zip(outputs, targets):\n",
    "#         loss += loss_fn(out, target)\n",
    "        \n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     return outputs, loss.data[0]\n",
    "\n",
    "# def train(inputs, targets, n_epochs = 100, print_every = 10):\n",
    "#     total_loss = 0.0\n",
    "#     for epoch in range(1, n_epochs + 1):\n",
    "#         output, loss = run_epoch(inputs, targets)\n",
    "#         if epoch % print_every == 0:\n",
    "#             print('Epoch: %2i / Loss: %.7f' % (epoch, loss))\n",
    "            \n",
    "# def test(input_sent):\n",
    "#     h, c = rnn.init_h0c0()\n",
    "#     seq_len = input_sent.size()[0]\n",
    "#     input_sent = Variable(input_sent.view(seq_len, batch_size, -1))\n",
    "    \n",
    "#     output, h, c = rnn(input_sent, h, c)\n",
    "#     _, argmaxs = torch.max(output, dim = 0)\n",
    "    \n",
    "#     # flatten the sorted indices\n",
    "#     sent = argmaxs.view(-1).data.cpu().numpy().tolist()\n",
    "#     for i in sent:\n",
    "#         print(vocab[i],end=' ')\n",
    "        \n",
    "# # run_epoch(inputs, targets)\n",
    "# train(inputs, targets, n_epochs = 1000, print_every = 100)\n",
    "# torch.manual_seed(7)\n",
    "# test(inputs[0].cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNSentenceEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def init_s0(self):\n",
    "        '''Produces a start-of-document character'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class SentenceExtractor(nn.Module):\n",
    "    \n",
    "#     def __init__(self, input_size, hidden_size, num_layers = 1):\n",
    "#         super().__init__()\n",
    "#         # arguments\n",
    "#         self.input_size = input_size \n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "        \n",
    "#         # parameters\n",
    "#         self.w_y = nn.Parameter(torch.randn(1, hidden_size * 2))\n",
    "        \n",
    "#         # layers and operations\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "#         if torch.cuda.is_available():\n",
    "#             self.cuda()\n",
    "            \n",
    "#     def forward(self, s, h_bar, c_bar, h, p):\n",
    "#         '''\n",
    "#         Args:\n",
    "#             # Raw Inputs\n",
    "#             s: (seq_len) x (batch_size) x (input_size). s_t.\n",
    "#             h: (seq_len) x (num_layers) x (batch_size) x (hidden_size). h_t from the encoder.\n",
    "            \n",
    "#             # Previous hidden states\n",
    "#             h_bar: (num_layers=1) x (batch_size) x (hidden_size)\n",
    "#             c_bar: (num_layers=1) x (batch_size) x (hidden_size)\n",
    "            \n",
    "#             p: (batch_size) x (1). torch FloatTensor.\n",
    "            \n",
    "#         Returns:\n",
    "#             output\n",
    "#         '''\n",
    "        \n",
    "#         s_weighted = p.unsqueeze(0).expand(s.size()) * s\n",
    "#         output, (h_bar,c_bar) = self.lstm(s_weighted, (h_bar, c_bar))\n",
    "        \n",
    "#         # h_cat: batch_size x hidden_size*2 x 1\n",
    "#         h_cat = torch.cat((h, h_bar), dim = -1).squeeze(0).unsqueeze(-1)\n",
    "        \n",
    "#         # batch_size x 1 x hidden_size*2\n",
    "#         w_y = self.w_y\n",
    "#         W_y = w_y.expand(h_cat.size(0), w_y.size(0), w_y.size(1))\n",
    "        \n",
    "#         # batch_size x 1. torch.bmm is a batch matrix multiplication\n",
    "#         logit = torch.bmm(W_y, h_cat).view(-1, 1)\n",
    "        \n",
    "#         # batch_size x 1\n",
    "#         p = self.sigmoid(logit)\n",
    "        \n",
    "#         return p, output, h_bar, c_bar\n",
    "    \n",
    "#     def init_p(self, h0, hn):\n",
    "#         '''\n",
    "#         Args:\n",
    "#             h0: initial hidden state from the encoder.\n",
    "#             (num_layers=1) x (batch_size) x (hidden_size)\n",
    "#             hn: final hidden state from the encoder. \n",
    "#             (num_layers=1) x (batch_size) x (hidden_size)\n",
    "            \n",
    "#         Returns:\n",
    "#             p0: initial probability. (batch_size) x 1\n",
    "#         '''\n",
    "#         # h_cat: batch_size x hidden_size*2 x 1\n",
    "#         h_cat = torch.cat((h0, hn), dim = -1).squeeze(0).unsqueeze(-1)\n",
    "        \n",
    "#         # batch_size x 1 x hidden_size*2\n",
    "#         w_y = self.w_y\n",
    "#         W_y = w_y.expand(batch_size, w_y.size(0), w_y.size(1))\n",
    "        \n",
    "#         # batch_size x 1. torch.bmm is a batch matrix multiplication\n",
    "#         logit = torch.bmm(W_y, h_cat).view(-1, 1)\n",
    "        \n",
    "#         # batch_size x 1\n",
    "#         p0 = self.sigmoid(logit)\n",
    "        \n",
    "#         if torch.cuda.is_available():\n",
    "#             p0 = p0.cuda()\n",
    "        \n",
    "#         return p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentenceExtractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-6ed25a3e9d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocumentEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mminibatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SentenceExtractor' is not defined"
     ]
    }
   ],
   "source": [
    "# from torch.nn.utils.rnn import pad_packed_sequence\n",
    "# from custom_utils.packing import pack, unpack\n",
    "# input_size = vocab.V\n",
    "# hidden_size = 100\n",
    "# num_layers = 1\n",
    "# batch_size = 2\n",
    "\n",
    "# encoder = DocumentEncoder(input_size, hidden_size, num_layers)\n",
    "# decoder = SentenceExtractor(input_size, hidden_size)\n",
    "    \n",
    "# for minibatch in generate_batch(input_docs, target_docs, batch_size):\n",
    "#     input, target = minibatch\n",
    "    \n",
    "#     # Initialize the encoder\n",
    "#     h_e, c_e = encoder.init_h0c0(batch_size)\n",
    "#     h_e0 = Variable(h_e.data)\n",
    "    \n",
    "#     # A minibatch goes through the encoder\n",
    "#     input_packed, orders = pack(input)\n",
    "#     output_packed, hn, cn = encoder(input_packed, h_e, c_e)\n",
    "#     output_unpacked, length = pad_packed_sequence(output_packed)\n",
    "#     # h1, h2, ....hn for each documents\n",
    "# #     encoder_hiddens = unpack(output_packed, orders)\n",
    "# #     print(encoder_hiddens)\n",
    "#     print(output_unpacked.size())\n",
    "# #     print(output_packed.data)\n",
    "    \n",
    "    \n",
    "#     # Initialize the decoder\n",
    "#     ## calculate p0, h_bar0, c_bar0\n",
    "#     h_bar = h_e\n",
    "#     c_bar = c_e\n",
    "# #     print(h_bar.size())\n",
    "#     p = decoder.init_p(h_e0, h_bar)\n",
    "#     ## calculate p1, h_bar1, c_bar1\n",
    "# #     h = encoder_hiddens[0]\n",
    "# #     print(h.size())\n",
    "# #     for b, enc_hidden in enumerate(encoder_hiddens):\n",
    "#     input_unpacked, length = pad_packed_sequence(input_packed)\n",
    "#     p, output_unmasked, h_bar, c_bar = decoder(input_unpacked, h_bar, c_bar, h_e, p)\n",
    "#     output_masked = output_unmasked\n",
    "    \n",
    "#     print(output.size())\n",
    "    \n",
    "#     # A minibatch goes through the decoder\n",
    "#     ## WARNING: input should include the representation for s0\n",
    "# #     input_packed, orders = pack(input)\n",
    "# #     p, h_bar, c_bar = decoder(input_packed, h_bar, c_bar, h, p)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
