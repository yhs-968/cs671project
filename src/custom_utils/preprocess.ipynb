{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, wordpunct_tokenize\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Vocab:\n",
    "    '''Abstract vocabulary class that has useful helper functions\n",
    "    '''\n",
    "    def __init__(self, corpus, top_k = None, case_sensitive = False):\n",
    "        '''\n",
    "        Builds a vocabulary, using the words in the corpus\n",
    "\n",
    "        Args:\n",
    "            corpus: string of text.\n",
    "            top_k: the number of words to be included in the vocabulary, including the special tokens:\n",
    "            \"UNK(unknown)\", \"_BEGIN_(beginning of a sentence)\", \"_END_(end of a sentence)\"\n",
    "\n",
    "        Returns:\n",
    "            word2id: dictionary of (word, id) pairs\n",
    "            id2word: list of words in the vocabulary\n",
    "        '''\n",
    "        if type(top_k) == int:\n",
    "            top_k -= 3\n",
    "        if not case_sensitive:\n",
    "            corpus = corpus.lower()\n",
    "        \n",
    "        word_counts = Counter(wordpunct_tokenize(corpus)).most_common(top_k)\n",
    "\n",
    "        id2word = sorted([word for word,count in word_counts]) + ['UNK','_BEGIN_','_END_']\n",
    "        word2id = {word: i for i, word in enumerate(id2word)}\n",
    "\n",
    "        self.id2word = id2word\n",
    "        self.word2id = word2id\n",
    "        self.V = len(id2word)\n",
    "\n",
    "    def sents2id(self, text, top_k = None, case_sensitive = False):\n",
    "        '''Tokenizes a text into sentences, mapping the words to corresponding indices.\n",
    "\n",
    "        Args:\n",
    "            text: string.\n",
    "\n",
    "        Returns:\n",
    "            sents_list: List of sentences, where each sentences are the list of word indices.\n",
    "        '''\n",
    "        word2id = self.word2id\n",
    "        id2word = self.id2word\n",
    "        \n",
    "        if not case_sensitive:\n",
    "            text = text.lower()\n",
    "        \n",
    "        sents = sent_tokenize(text)\n",
    "\n",
    "        sents_list = []\n",
    "        for i in range(len(sents)):\n",
    "            sent = wordpunct_tokenize(sents[i])\n",
    "            sent = [word2id[word] if word in word2id else word2id['UNK'] for word in sent]\n",
    "            sent = [word2id['_BEGIN_']] + sent + [word2id['_END_']]\n",
    "            sents_list.append(sent)\n",
    "\n",
    "        return sents_list\n",
    "\n",
    "    def id2sents(self, sents):\n",
    "        '''Returns the string representation of the sentences, where sentences is a list of sentences\n",
    "        and each sentences are lists of word ids.\n",
    "\n",
    "        Args:\n",
    "            sents: a list of word ids in the dictionary\n",
    "\n",
    "        Returns:\n",
    "            sents_str: string representation of sentences.\n",
    "        '''\n",
    "\n",
    "        return ' '.join([self.id2word[i_word] for i_word in chain(*sents)])\n",
    "\n",
    "    def sent2onehot(self, tokens):\n",
    "        '''\n",
    "        Converts the list of word indices into the corresponding list of one-hot vectors\n",
    "\n",
    "        Args:\n",
    "            tokens: a sequence of word indices\n",
    "\n",
    "        Returns:\n",
    "            onehots: a sequence of one-hot vectors corresponding to tokens.\n",
    "        '''\n",
    "        onehots = []\n",
    "        for i in tokens:\n",
    "            vec = np.zeros(shape=self.V, dtype=int)\n",
    "            vec[i] = 1\n",
    "            onehots.append(vec)\n",
    "\n",
    "        onehots = torch.from_numpy(np.vstack(onehots)).type(torch.FloatTensor)\n",
    "        return onehots\n",
    "\n",
    "    def onehot2sent(self, vecs):\n",
    "        '''\n",
    "        Converts a sequence of one-hot vectors into a sequence of word indices\n",
    "\n",
    "        Args:\n",
    "            vecs: a sequence of one-hot vectors. \n",
    "            Should be a torch tensor where each rows correspond to a one-hot vector of a word.\n",
    "\n",
    "        Returns:\n",
    "            sent: a list of word indices that corresponds to vecs\n",
    "        '''\n",
    "        maxs, argmaxs = torch.max(vecs, dim = 1) # dim: axis to get argmaxs\n",
    "\n",
    "        sent = [self[i] for i in argmaxs]\n",
    "        return sent\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.word2id)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if type(key) == int:\n",
    "            return self.id2word[key]\n",
    "        elif type(key) == str:\n",
    "            return self.word2id[key]\n",
    "        else:\n",
    "            print('Wrong type')\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = 'Deep learning (also known as deep structured learning or hierarchical learning) \\\n",
    "is part of a broader family of machine learning methods based on learning data representations, \\\n",
    "as opposed to task-specific algorithms. Learning can be supervised, partially supervised or unsupervised.\\\n",
    " Some representations are loosely based on interpretation of information processing and communication patterns \\\n",
    " in a biological nervous system, such as neural coding that attempts to define a relationship between various \\\n",
    " stimuli and associated neuronal responses in the brain. Research attempts to create efficient systems to \\\n",
    " learn these representations from large-scale, unlabeled data sets. Deep learning architectures such as \\\n",
    " deep neural networks, deep belief networks and recurrent neural networks have been applied to fields \\\n",
    " including computer vision, speech recognition, natural language processing, audio recognition, social \\\n",
    " network filtering, machine translation, bioinformatics and drug design .where they produced results \\\n",
    " comparable to and in some cases superior to human experts.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107, 33, 55, 0, 7, 51, 12, 33, 88, 55, 68, 44, 55, 1, 50, 69, 65, 5, 24, 39, 65, 57, 55, 58, 16, 66, 55, 32, 77, 2, 12, 67, 99, 94, 3, 85, 6, 4, 108], [107, 55, 25, 17, 91, 2, 70, 91, 68, 102, 4, 108], [107, 84, 77, 11, 56, 16, 66, 49, 65, 48, 72, 8, 28, 71, 46, 5, 22, 60, 92, 2, 89, 12, 63, 27, 95, 14, 99, 34, 5, 76, 20, 103, 87, 8, 13, 64, 79, 46, 96, 23, 4, 108], [107, 78, 14, 99, 31, 37, 93, 99, 54, 97, 77, 42, 53, 3, 81, 2, 101, 32, 82, 4, 108], [107, 33, 55, 10, 89, 12, 33, 63, 62, 2, 33, 19, 62, 8, 75, 63, 62, 43, 18, 9, 99, 40, 47, 30, 104, 2, 86, 74, 2, 59, 52, 72, 2, 15, 74, 2, 83, 61, 41, 2, 57, 100, 2, 21, 8, 36, 35, 4, 105, 98, 73, 80, 29, 99, 8, 46, 84, 26, 90, 99, 45, 38, 4, 108]]\n",
      "_BEGIN_ deep learning ( also known as deep structured learning or hierarchical learning ) is part of a broader family of machine learning methods based on learning data representations , as opposed to task - specific algorithms . _END_ _BEGIN_ learning can be supervised , partially supervised or unsupervised . _END_ _BEGIN_ some representations are loosely based on interpretation of information processing and communication patterns in a biological nervous system , such as neural coding that attempts to define a relationship between various stimuli and associated neuronal responses in the brain . _END_ _BEGIN_ research attempts to create efficient systems to learn these representations from large - scale , unlabeled data sets . _END_ _BEGIN_ deep learning architectures such as deep neural networks , deep belief networks and recurrent neural networks have been applied to fields including computer vision , speech recognition , natural language processing , audio recognition , social network filtering , machine translation , bioinformatics and drug design . where they produced results comparable to and in some cases superior to human experts . _END_\n"
     ]
    }
   ],
   "source": [
    "sents = vocab.sents2id(corpus)\n",
    "print(sents)\n",
    "print(vocab.id2sents(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "')'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[')']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39, 109])\n",
      "['_BEGIN_', 'deep', 'learning', '(', 'also', 'known', 'as', 'deep', 'structured', 'learning', 'or', 'hierarchical', 'learning', ')', 'is', 'part', 'of', 'a', 'broader', 'family', 'of', 'machine', 'learning', 'methods', 'based', 'on', 'learning', 'data', 'representations', ',', 'as', 'opposed', 'to', 'task', '-', 'specific', 'algorithms', '.', '_END_']\n"
     ]
    }
   ],
   "source": [
    "onehot = vocab.sent2onehot(sents[0])\n",
    "print(onehot.size())\n",
    "print(vocab.onehot2sent(onehot))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
